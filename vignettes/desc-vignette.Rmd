---
title: "Descriptive Statistic Layers"
output: 
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{Descriptive Statistic Layers}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, include=FALSE}
library(tidyverse) 
library(magrittr)
library(Tplyr)
library(knitr)
load("adlb.Rdata")
load("adsl.Rdata")
```

Descriptive statistics in 'Tplyr' are created using `group_desc` function when creating a layer. While `group_desc` allows you to set your target, by variables, and filter criteria, a great deal of the control of the layer comes from `set_format_strings` where the actual summaries are declared. 

```{r intro}
tplyr_table(adsl, TRT01P) %>% 
  add_layer(
    group_desc(AGE, by = "Age (years)", where= SAFFL=="Y") %>% 
      set_format_strings(
        "n"        = f_str("xx", n),
        "Mean (SD)"= f_str("xx.x (xx.xx)", mean, sd),
        "Median"   = f_str("xx.x", median),
        "Q1, Q3"   = f_str("xx, xx", q1, q3),
        "Min, Max" = f_str("xx, xx", min, max),
        "Missing"  = f_str("xx", missing)
      )
  ) %>% 
  build() %>% 
  kable()

```

The settings above are actually the 'Tplyr' default, so if these are the results you desire, then there's no need to use `set_format_strings` at all - and just the `group_desc` call can be used. But let's walk through this call to `set_format_strings` to understand in detail what's going on:

1) The quotes strings on the left of the '=', to name each parameter, become the row label in the output. This allows you to define in `set_format_strings` some custom text to explain the summary that is presented on the associated row. This text is fully in your control.
2) On the right side of each equals is a call to `f_str`. As explained in the 'Getting Started' vignette, this is an object that captures a lot of metadata to understand how the strings should be presented. 
3) Within the `f_str` call, you see x's in quotes. This defines how you'd like the numbers formatted from the resulting summaries. The number of x's you use on the left side of a decimal control the space allotted for an integer, and the right side controls the decimal precision. Decimals are rounded prior to string formatting - so no need to worry about that. Note that this forcefully sets the decimal and integer precision - 'Tplyr' can automatically determine this for you as well, but more on that later.
4) After the x's there are unquoted variable names. This is where you specify the actual summaries that will be performed. Notice that some `f_str` calls have two summaries specified. This allows you to put two summaries in the same string and present them on the same line. 

But where do these summary names come from? And which ones does 'Tplyr' have? 

## Built-in Summaries

We've built a number of default summaries into 'Tplyr', which allows you to perform these summaries without having to specify the functions to calculate them yourself. The summaries built in to 'Tplyr' are listed below. In the second column are the names that you would use within an `f_str` call to use them. In the third column, we have the syntax used to make the function call.

```{r varnames, echo=FALSE}
x <- data.frame(
  Statistic = c('N', 'Mean', "Standard Deviation", "Median", "Variance", "Minimum",
                "Maximum", "Interquartile Range", "Q1", "Q3", "Missing"),
  `Variable Names` = c("n", "mean", "sd", "median", "variance", "min", "max", "iqr", "q1", "q3", "missing"),
  `Function Call` = c("n()", "mean(.var, na.rm=TRUE)", "sd(.var, na.rm=TRUE)", "median(.var, na.rm=TRUE)",
                      "var(.var, na.rm=TRUE)", "min(.var, na.rm=TRUE)", "max(.var, na.rm=TRUE)", 
                      "IQR(.var, na.rm=TRUE, type=getOption('tplyr.quantile_type')",
                      "quantile(.var, na.rm=TRUE, type=getOption('tplyr.quantile_type'))[[2]]", 
                      "quantile(.var, na.rm=TRUE, type=getOption('tplyr.quantile_type'))[[4]]", 
                      "sum(is.na(.var))")
)

x %>% 
  kable(align="ccl", col.names=c('Statistic', 'Variable Names', 'Function Call'))

```

### Notes About Built-in's

Note that the only non-default option being used in any of the function calls above is `na.rm=TRUE`. For most of the functions, this is likely fine - but with IQR, Q1, and Q3 note that there are several different quantile algorithms available in R. The default we chose to use is the R default of Type 7:

$$
m = 1-p. p[k] = (k - 1) / (n - 1). \textrm{In this case, } p[k] = mode[F(x[k])]. \textrm{This is used by S.}
$$
That said, we still want to offer some flexibility here, so you can change the quantile algorithm by switching the `tplyr.quantile_type` option. If you're intending to match the SAS definition, you can use Type 3. For more information, see the `quantile` documentation. 

The example below demonstrates using the default quantile algorithm in R

```{r quantile_types_default}
tplyr_table(adsl, TRT01P) %>% 
  add_layer(
    group_desc(CUMDOSE) %>% 
      set_format_strings("Q1, Q3" = f_str('xxxxx, xxxxx', q1, q3))
  ) %>% 
  build() %>%
  select(-starts_with("ord")) %>% 
  kable()
```

This next example demonstrates using quantile algorithm Type 3, which matches the SAS definition.

```{r quantile_types_sas}
options(tplyr.quantile_type = 3)
tplyr_table(adsl, TRT01P) %>% 
  add_layer(
    group_desc(CUMDOSE) %>% 
      set_format_strings("Q1, Q3" = f_str('xxxxx, xxxxx', q1, q3))
  ) %>% 
  build() %>% 
    select(-starts_with("ord")) %>% 
  kable()
```

```{r echo=FALSE}
options(tplyr.quantile_type=7)
```

It's up to you to determine which algorithm you should use - but we found it necessary to provide you with the flexibility to change this within the default summaries.

## Custom Summaries

You can see that there was a  lot of attention given to counting over the past three weeks - but descriptive statistics weren't neglected either. Let's start simple - custom summaries no work properly on multi-variable summaries:

```{r multi-custom}
tplyr_table(adsl, TRT01P) %>%
  add_layer(
    group_desc(vars(AGE, HEIGHTBL), by = "Sepal Length") %>%
      set_custom_summaries(
        geometric_mean = exp(sum(log(.var[.var > 0]), na.rm=TRUE) / length(.var))
      ) %>%
      set_format_strings(
        'Geometric Mean (SD)' = f_str('xx.xx (xx.xxx)', geometric_mean, sd)
      )
  ) %>% 
  build() %>% 
  select(-starts_with("ord"))
  kable()

```

Not much more to it! Just use `.var` instead of the a distinct variable name. 

## Formatting 

## Auto Precision

The more interesting development for descriptive statistics was the addition of auto-precision. Auto-precision allows you to format your numeric summaries based on the precision of the data collected. Particularly when working with labs results, different tests may have difference necessities for decimal precision depending on the numeric range of the tests, the units the data are collected in, etc. So it is common practice to vary the precision of the data being presented based on the data collected. Furthermore, depending on the summary being presented, you may wish to increase the precision further. For example, you may want the mean to be at collected precision +1 decimal place, for standard deviation +2. 

Tplyr now handles these cases, and in Tplyr style, it's intuitive and easy to control. This has all been built into the format strings, because a natural place to specify your desired format is where you specify how you want your data presented. Now - if you wish to use auto-precision, use `a` instead of `x` when creating your summaries. Note that only one `a` is needed. To use increased precision, use `a+n` where `n` is the number of additional spaces you wish to add. 

```{r autoprecision1}

tplyr_table(adlb, TRTA) %>% 
  add_layer(
    group_desc(AVAL, by = PARAMCD) %>% 
      set_format_strings(
        'Mean (SD)' = f_str('a.a+1 (a.a+2)', mean, sd)
      )
  ) %>% 
  build() %>% 
  kable()

```

As you can see, the decimal precision is now varying depending on the test being performed. Notice that both the integer and the decimal side of each number fluctuate as well. Tpylr collects both the integer and decimal precision, and you can specify both separately. For example, you could use `x`'s to specify a default number of spaces for your integers that are used consistently across by variables, but vary the decimal precision based on collected data. You can also increment the number of spaces for both integer and decimal separately. 

But - this is kind of ugly, isn't it? Do we really need all 5 decimal places collected for CA? For this reason, you're able to set a cap on the precision that's displayed:

```{r autoprecision2}
tplyr_table(adlb, TRTA) %>% 
  add_layer(
    group_desc(AVAL, by = PARAMCD) %>% 
      set_format_strings(
        'Mean (SD)' = f_str('a.a+1 (a.a+2)', mean, sd),
        cap = c(int=3, dec=2)
      )
  ) %>% 
  build() %>% 
  head() %>% 
  kable()

```

Now that looks better. The `cap` argument is part of `set_format_strings`. You need to specify the integer and decimal caps separately. Note that integer precision might not behave like you expect - it doesn't make sense to truncate an integer if it's value is too high, so if the integer exceeds the allotted space, then the length of the string will increase and the full value will be displayed. But values that are short enough will only pad to the capped number of spaces. We plan to implement a warning in future releases if integers exceed the set display space allocation. 

This was a basic situation, but if you're paying close attention, you may have some questions. What if you have more by variables, like by visit AND test. Do we then calculate precision by visit and test? What if collected precision is different per visit and we don't want that? What about multiple summary variable? How do we determine precision then? We have modifier functions for this:

```{r precision3}
tplyr_table(adlb, TRTA, where = SAFFL=='Y' & AVISIT != '') %>% 
  add_layer(
    group_desc(vars(AVAL, CHG, BASE), by = vars(AVISIT,PARAMCD)) %>% 
      set_format_strings(
        'Mean (SD)' = f_str('a.a+1 (a.a+2)', mean, sd),
        cap = c(int=3, dec=2)
      ) %>% 
      set_precision_on(AVAL) %>% 
      set_precision_by(PARAMCD)
  ) %>%
  build() %>% 
  head() %>% 
  kable()

```

Three variables are being summarized here - AVAL, CHG, and BASE. So which should be used for precision? `set_precision_on` allows you to specify this, where the `precision_on` variable must be one of the variables within `target_var`. Similarly, `set_precision_by` changes the `by` variables used to determine collected precision. If no `precision_on` variable is specified, the first variable in `target_var` is used. If not `precision_by` variables are specified, then the default `by` variables are used.
